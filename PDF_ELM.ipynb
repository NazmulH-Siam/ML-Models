{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZsV8QUuovnlMNHYOoQeQi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"et-ZxtPtvlWb","executionInfo":{"status":"ok","timestamp":1722025038935,"user_tz":180,"elapsed":8396,"user":{"displayName":"Nazmul H. Siam","userId":"01851349013009671388"}},"outputId":"dd81faf7-1b61-4b8a-a17f-058f0523bde7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Collecting hpelm\n","  Downloading hpelm-1.0.10-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n","Collecting fasteners (from hpelm)\n","  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n","Collecting nose (from hpelm)\n","  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hpelm) (1.16.0)\n","Requirement already satisfied: tables in /usr/local/lib/python3.10/dist-packages (from hpelm) (3.8.0)\n","Requirement already satisfied: cython>=0.29.21 in /usr/local/lib/python3.10/dist-packages (from tables->hpelm) (3.0.10)\n","Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from tables->hpelm) (2.10.1)\n","Requirement already satisfied: blosc2~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from tables->hpelm) (2.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tables->hpelm) (24.1)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from tables->hpelm) (9.0.0)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from blosc2~=2.0.0->tables->hpelm) (1.0.8)\n","Downloading hpelm-1.0.10-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n","Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nose, fasteners, hpelm\n","Successfully installed fasteners-0.19 hpelm-1.0.10 nose-1.3.7\n"]}],"source":["pip install pandas numpy scikit-learn nltk hpelm\n"]},{"cell_type":"code","source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n","from sklearn.model_selection import StratifiedKFold\n","from hpelm import ELM\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from sklearn.feature_extraction.text import HashingVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","from scipy.sparse import hstack, csr_matrix\n","\n","# Download NLTK data\n","nltk.download('punkt')\n","\n","# Load the dataset\n","file_path = '/content/PDFMalware2022.csv'\n","df = pd.read_csv(file_path)\n","\n","# Handle missing values\n","# Fill missing categorical values with the mode value of each column\n","categorical_cols = ['File name', 'text', 'header']\n","df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n","\n","# Check for and handle missing values in the target column\n","if df['Class'].isnull().any():\n","    print(\"Found NaN values in the target column. Filling with mode value.\")\n","    df['Class'] = df['Class'].fillna(df['Class'].mode()[0])\n","\n","# Encode target variable\n","df['Class'] = df['Class'].replace({1: 1, 2: 2})\n","\n","# Tokenization and Hashing Vectorizer for text columns\n","text_cols = ['File name', 'text', 'header']\n","hashing_vectorizer = HashingVectorizer(n_features=2**16, alternate_sign=False)\n","\n","# Apply tokenization and vectorization\n","text_features = [hashing_vectorizer.transform(df[col].apply(lambda x: ' '.join(word_tokenize(x)))) for col in text_cols]\n","\n","# Combine text features into a single sparse matrix\n","text_features_combined = hstack(text_features)\n","\n","# Separate features and target\n","y = df['Class'].values\n","\n","# Combine text features (no numerical features in this dataset)\n","X = text_features_combined\n","\n","# Reduce dimensionality with Truncated SVD\n","svd = TruncatedSVD(n_components=100, random_state=42)\n","X_reduced = svd.fit_transform(X)\n","\n","# Adjust labels for one-hot encoding\n","y_adjusted = y - 1\n","\n","# One-hot encode the target labels\n","one_hot_encoder = OneHotEncoder(sparse_output=False)\n","y_one_hot = one_hot_encoder.fit_transform(y_adjusted.reshape(-1, 1))\n","\n","# 10-fold cross-validation\n","skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","f1_scores = []\n","classification_reports = []\n","\n","for fold, (train_index, test_index) in enumerate(skf.split(X_reduced, y)):\n","    X_train, X_test = X_reduced[train_index], X_reduced[test_index]\n","    y_train, y_test = y_one_hot[train_index], y_one_hot[test_index]\n","\n","    # Print training and testing sizes\n","    print(f\"Fold {fold + 1}:\")\n","    print(f\"Training size: {X_train.shape[0]}\")\n","    print(f\"Testing size: {X_test.shape[0]}\")\n","\n","    # Train an ELM model\n","    # Initialize ELM\n","    elm_model = ELM(X_train.shape[1], y_train.shape[1], classification=\"c\", batch=1, accelerator=\"CPU\")\n","\n","    # Add hidden neurons, e.g., 100 neurons with sigmoid activation function\n","    elm_model.add_neurons(100, \"sigm\")\n","\n","    # Train the ELM model\n","    elm_model.train(X_train, y_train, \"c\")\n","\n","    # Predict using the trained model\n","    y_pred_train = elm_model.predict(X_train)\n","    y_pred_test = elm_model.predict(X_test)\n","\n","    # Convert predictions to class labels\n","    y_pred_train_labels = y_pred_train.argmax(axis=1)\n","    y_pred_test_labels = y_pred_test.argmax(axis=1)\n","\n","    # Convert one-hot encoded y_test back to class labels for evaluation\n","    y_test_labels = y_test.argmax(axis=1)\n","\n","    # Adjust predicted labels back to original range (1 and 2)\n","    y_pred_test_labels_adjusted = y_pred_test_labels + 1\n","    y_test_labels_adjusted = y_test_labels + 1\n","\n","    # Evaluate the model\n","    accuracy = accuracy_score(y_test_labels_adjusted, y_pred_test_labels_adjusted)\n","    precision = precision_score(y_test_labels_adjusted, y_pred_test_labels_adjusted, average='weighted')\n","    recall = recall_score(y_test_labels_adjusted, y_pred_test_labels_adjusted, average='weighted')\n","    f1 = f1_score(y_test_labels_adjusted, y_pred_test_labels_adjusted, average='weighted')\n","    report = classification_report(y_test_labels_adjusted, y_pred_test_labels_adjusted, output_dict=True)\n","\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    f1_scores.append(f1)\n","    classification_reports.append(report)\n","\n","    print(f\"Fold {fold + 1} Results:\")\n","    print(f\"Accuracy: {accuracy}\")\n","    print(f\"Precision: {precision}\")\n","    print(f\"Recall: {recall}\")\n","    print(f\"F1 Score: {f1}\\n\")\n","\n","# Aggregate the classification reports\n","average_classification_report = {}\n","for key in classification_reports[0].keys():\n","    if isinstance(classification_reports[0][key], dict):\n","        average_classification_report[key] = {}\n","        for sub_key in classification_reports[0][key].keys():\n","            average_classification_report[key][sub_key] = np.mean([report[key][sub_key] for report in classification_reports])\n","    else:\n","        average_classification_report[key] = np.mean([report[key] for report in classification_reports])\n","\n","# Calculate average metrics\n","average_accuracy = np.mean(accuracy_scores)\n","average_precision = np.mean(precision_scores)\n","average_recall = np.mean(recall_scores)\n","average_f1_score = np.mean(f1_scores)\n","\n","print(f\"Average Model Accuracy: {average_accuracy}\")\n","print(f\"Average Precision: {average_precision}\")\n","print(f\"Average Recall: {average_recall}\")\n","print(f\"Average F1 Score: {average_f1_score}\")\n","print(\"Average Classification Report:\")\n","for key, value in average_classification_report.items():\n","    if isinstance(value, dict):\n","        print(f\"  {key}:\")\n","        for sub_key, sub_value in value.items():\n","            print(f\"    {sub_key}: {sub_value}\")\n","    else:\n","        print(f\"  {key}: {value}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w4Iaj5WRv7DK","executionInfo":{"status":"ok","timestamp":1722025206683,"user_tz":180,"elapsed":27903,"user":{"displayName":"Nazmul H. Siam","userId":"01851349013009671388"}},"outputId":"87270baa-9a76-4afa-ea9b-488a4b20fda0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Found NaN values in the target column. Filling with mode value.\n","Fold 1:\n","Training size: 9023\n","Testing size: 1003\n","Fold 1 Results:\n","Accuracy: 0.7876370887337986\n","Precision: 0.7914064081292582\n","Recall: 0.7876370887337986\n","F1 Score: 0.7843877555878361\n","\n","Fold 2:\n","Training size: 9023\n","Testing size: 1003\n","Fold 2 Results:\n","Accuracy: 0.7666999002991027\n","Precision: 0.7693964348395147\n","Recall: 0.7666999002991027\n","F1 Score: 0.7631954975409905\n","\n","Fold 3:\n","Training size: 9023\n","Testing size: 1003\n","Fold 3 Results:\n","Accuracy: 0.7676969092721835\n","Precision: 0.773708605691218\n","Recall: 0.7676969092721835\n","F1 Score: 0.7627282153352976\n","\n","Fold 4:\n","Training size: 9023\n","Testing size: 1003\n","Fold 4 Results:\n","Accuracy: 0.7666999002991027\n","Precision: 0.7704927347383724\n","Recall: 0.7666999002991027\n","F1 Score: 0.7626580538719054\n","\n","Fold 5:\n","Training size: 9023\n","Testing size: 1003\n","Fold 5 Results:\n","Accuracy: 0.7796610169491526\n","Precision: 0.7836588559314747\n","Recall: 0.7796610169491526\n","F1 Score: 0.7760379037577331\n","\n","Fold 6:\n","Training size: 9023\n","Testing size: 1003\n","Fold 6 Results:\n","Accuracy: 0.7627118644067796\n","Precision: 0.7701202289283127\n","Recall: 0.7627118644067796\n","F1 Score: 0.7569125435606583\n","\n","Fold 7:\n","Training size: 9024\n","Testing size: 1002\n","Fold 7 Results:\n","Accuracy: 0.7564870259481038\n","Precision: 0.7605792808607518\n","Recall: 0.7564870259481038\n","F1 Score: 0.7517886817726672\n","\n","Fold 8:\n","Training size: 9024\n","Testing size: 1002\n","Fold 8 Results:\n","Accuracy: 0.7495009980039921\n","Precision: 0.7524894068350776\n","Recall: 0.7495009980039921\n","F1 Score: 0.7450528788206046\n","\n","Fold 9:\n","Training size: 9024\n","Testing size: 1002\n","Fold 9 Results:\n","Accuracy: 0.7664670658682635\n","Precision: 0.7734154275362528\n","Recall: 0.7664670658682635\n","F1 Score: 0.7610983359329763\n","\n","Fold 10:\n","Training size: 9024\n","Testing size: 1002\n","Fold 10 Results:\n","Accuracy: 0.7684630738522954\n","Precision: 0.7710278436297021\n","Recall: 0.7684630738522954\n","F1 Score: 0.7651256321678829\n","\n","Average Model Accuracy: 0.7672024843632774\n","Average Precision: 0.7716295227119934\n","Average Recall: 0.7672024843632774\n","Average F1 Score: 0.762898549834855\n","Average Classification Report:\n","  1:\n","    precision: 0.7500355857278154\n","    recall: 0.8702773997018601\n","    f1-score: 0.8056406638860848\n","    support: 555.8\n","  2:\n","    precision: 0.7984888448448042\n","    recall: 0.6389808489080167\n","    f1-score: 0.7097275458872747\n","    support: 446.8\n","  accuracy: 0.7672024843632774\n","  macro avg:\n","    precision: 0.7742622152863098\n","    recall: 0.7546291243049384\n","    f1-score: 0.7576841048866797\n","    support: 1002.6\n","  weighted avg:\n","    precision: 0.7716295227119934\n","    recall: 0.7672024843632774\n","    f1-score: 0.762898549834855\n","    support: 1002.6\n"]}]}]}