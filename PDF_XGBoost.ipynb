{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOEoag+SQ1TgQR/NB6zi530"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XT5jjhVMBHnV","executionInfo":{"status":"ok","timestamp":1721869972501,"user_tz":180,"elapsed":7619,"user":{"displayName":"Nazmul H. Siam","userId":"01851349013009671388"}},"outputId":"d0a2db01-f2d2-4c8a-b1d3-b2d728628195"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}],"source":["pip install pandas numpy scikit-learn nltk scipy xgboost"]},{"cell_type":"code","source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n","from sklearn.feature_extraction.text import HashingVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","from scipy.sparse import hstack, csr_matrix\n","import xgboost as xgb\n","import gc\n","import nltk\n","from nltk.tokenize import word_tokenize\n","\n","# Download NLTK data\n","nltk.download('punkt')\n","\n","# Load the dataset\n","file_path = '/content/PDFMalware2022.csv'\n","df = pd.read_csv(file_path)\n","\n","# Handle missing values\n","# Fill missing categorical values with the mode value of each column\n","categorical_cols = ['File name', 'text', 'header']\n","df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n","\n","# Check for and handle missing values in the target column\n","if df['Class'].isnull().any():\n","    print(\"Found NaN values in the target column. Filling with mode value.\")\n","    df['Class'] = df['Class'].fillna(df['Class'].mode()[0])\n","\n","# Encode target variable\n","df['Class'] = df['Class'].replace({1: 1, 2: 2})\n","\n","# Tokenization and Hashing Vectorizer for text columns\n","text_cols = ['File name', 'text', 'header']\n","hashing_vectorizer = HashingVectorizer(n_features=2**10, alternate_sign=False)  # Reduced number of features for efficiency\n","\n","# Apply tokenization and vectorization\n","text_features = [hashing_vectorizer.transform(df[col].apply(lambda x: ' '.join(word_tokenize(x)))) for col in text_cols]\n","\n","# Combine text features into a single sparse matrix\n","text_features_combined = hstack(text_features)\n","\n","# Separate features and target\n","y = df['Class'].values\n","\n","# Combine text features (no numerical features in this dataset)\n","X = text_features_combined\n","\n","# Reduce dimensionality with Truncated SVD\n","svd = TruncatedSVD(n_components=100, random_state=42)\n","X_reduced = svd.fit_transform(X)\n","\n","# Adjust labels for one-hot encoding\n","y_adjusted = y - 1\n","\n","# 10-fold cross-validation\n","skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","f1_scores = []\n","classification_reports = []\n","\n","for fold, (train_index, test_index) in enumerate(skf.split(X_reduced, y)):\n","    X_train, X_test = X_reduced[train_index], X_reduced[test_index]\n","    y_train, y_test = y_adjusted[train_index], y_adjusted[test_index]\n","\n","    print(f\"Fold {fold + 1}:\")\n","    print(f\"Training data size: {len(train_index)}\")\n","    print(f\"Testing data size: {len(test_index)}\")\n","\n","    # Create DMatrix for XGBoost\n","    dtrain = xgb.DMatrix(X_train, label=y_train)\n","    dtest = xgb.DMatrix(X_test, label=y_test)\n","\n","    # Set XGBoost parameters\n","    params = {\n","        'objective': 'multi:softmax',\n","        'num_class': 2,\n","        'eval_metric': 'mlogloss',\n","        'eta': 0.1,\n","        'max_depth': 6\n","    }\n","\n","    # Train the model\n","    model = xgb.train(params, dtrain, num_boost_round=100)\n","\n","    # Predict using the trained model\n","    y_pred_test = model.predict(dtest)\n","\n","    # Adjust predicted labels back to original range (1 and 2)\n","    y_pred_test_labels_adjusted = y_pred_test + 1\n","    y_test_labels_adjusted = y_test + 1\n","\n","    # Evaluate the model\n","    accuracy = accuracy_score(y_test_labels_adjusted, y_pred_test_labels_adjusted)\n","    precision = precision_score(y_test_labels_adjusted, y_pred_test_labels_adjusted, average='weighted')\n","    recall = recall_score(y_test_labels_adjusted, y_pred_test_labels_adjusted, average='weighted')\n","    f1 = f1_score(y_test_labels_adjusted, y_pred_test_labels_adjusted, average='weighted')\n","    report = classification_report(y_test_labels_adjusted, y_pred_test_labels_adjusted, output_dict=True)\n","\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    f1_scores.append(f1)\n","    classification_reports.append(report)\n","\n","    print(f\"Fold {fold + 1} Results:\")\n","    print(f\"Accuracy: {accuracy}\")\n","    print(f\"Precision: {precision}\")\n","    print(f\"Recall: {recall}\")\n","    print(f\"F1 Score: {f1}\\n\")\n","\n","    # Free up memory\n","    del X_train, X_test, y_train, y_test, dtrain, dtest, model, y_pred_test\n","    gc.collect()\n","\n","# Aggregate the classification reports\n","average_classification_report = {}\n","for key in classification_reports[0].keys():\n","    if isinstance(classification_reports[0][key], dict):\n","        average_classification_report[key] = {}\n","        for sub_key in classification_reports[0][key].keys():\n","            average_classification_report[key][sub_key] = np.mean([report[key][sub_key] for report in classification_reports])\n","    else:\n","        average_classification_report[key] = np.mean([report[key] for report in classification_reports])\n","\n","# Calculate average metrics\n","average_accuracy = np.mean(accuracy_scores)\n","average_precision = np.mean(precision_scores)\n","average_recall = np.mean(recall_scores)\n","average_f1_score = np.mean(f1_scores)\n","\n","print(f\"Average Model Accuracy: {average_accuracy}\")\n","print(f\"Average Precision: {average_precision}\")\n","print(f\"Average Recall: {average_recall}\")\n","print(f\"Average F1 Score: {average_f1_score}\")\n","print(\"Average Classification Report:\")\n","for key, value in average_classification_report.items():\n","    if isinstance(value, dict):\n","        print(f\"  {key}:\")\n","        for sub_key, sub_value in value.items():\n","            print(f\"    {sub_key}: {sub_value}\")\n","    else:\n","        print(f\"  {key}: {value}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0dTrzNMvB6we","executionInfo":{"status":"ok","timestamp":1721870111233,"user_tz":180,"elapsed":92635,"user":{"displayName":"Nazmul H. Siam","userId":"01851349013009671388"}},"outputId":"3e7bc582-7dc6-463b-806e-d44365d3d29f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Found NaN values in the target column. Filling with mode value.\n","Fold 1:\n","Training data size: 9023\n","Testing data size: 1003\n","Fold 1 Results:\n","Accuracy: 0.7437686939182453\n","Precision: 0.7432108522075763\n","Recall: 0.7437686939182453\n","F1 Score: 0.7419610021693003\n","\n","Fold 2:\n","Training data size: 9023\n","Testing data size: 1003\n","Fold 2 Results:\n","Accuracy: 0.7298105682951147\n","Precision: 0.7288636414615817\n","Recall: 0.7298105682951147\n","F1 Score: 0.7283283161514824\n","\n","Fold 3:\n","Training data size: 9023\n","Testing data size: 1003\n","Fold 3 Results:\n","Accuracy: 0.7387836490528414\n","Precision: 0.738481364815577\n","Recall: 0.7387836490528414\n","F1 Score: 0.7364361583223864\n","\n","Fold 4:\n","Training data size: 9023\n","Testing data size: 1003\n","Fold 4 Results:\n","Accuracy: 0.7577268195413759\n","Precision: 0.7583716088321896\n","Recall: 0.7577268195413759\n","F1 Score: 0.7551555886128346\n","\n","Fold 5:\n","Training data size: 9023\n","Testing data size: 1003\n","Fold 5 Results:\n","Accuracy: 0.7278165503489531\n","Precision: 0.7268299404956406\n","Recall: 0.7278165503489531\n","F1 Score: 0.7266189982468478\n","\n","Fold 6:\n","Training data size: 9023\n","Testing data size: 1003\n","Fold 6 Results:\n","Accuracy: 0.7248255234297108\n","Precision: 0.7238354688420598\n","Recall: 0.7248255234297108\n","F1 Score: 0.7231584909595958\n","\n","Fold 7:\n","Training data size: 9024\n","Testing data size: 1002\n","Fold 7 Results:\n","Accuracy: 0.7305389221556886\n","Precision: 0.7296134084857032\n","Recall: 0.7305389221556886\n","F1 Score: 0.7288916884540777\n","\n","Fold 8:\n","Training data size: 9024\n","Testing data size: 1002\n","Fold 8 Results:\n","Accuracy: 0.7155688622754491\n","Precision: 0.7145798324731889\n","Recall: 0.7155688622754491\n","F1 Score: 0.7131810648473613\n","\n","Fold 9:\n","Training data size: 9024\n","Testing data size: 1002\n","Fold 9 Results:\n","Accuracy: 0.7345309381237525\n","Precision: 0.7339168966895446\n","Recall: 0.7345309381237525\n","F1 Score: 0.7325018503763429\n","\n","Fold 10:\n","Training data size: 9024\n","Testing data size: 1002\n","Fold 10 Results:\n","Accuracy: 0.7215568862275449\n","Precision: 0.7205277502036924\n","Recall: 0.7215568862275449\n","F1 Score: 0.7199319651201926\n","\n","Average Model Accuracy: 0.7324927413368677\n","Average Precision: 0.7318230764506755\n","Average Recall: 0.7324927413368677\n","Average F1 Score: 0.7306165123260422\n","Average Classification Report:\n","  1.0:\n","    precision: 0.7394761722960769\n","    recall: 0.7988466524078035\n","    f1-score: 0.7679769989299422\n","    support: 555.8\n","  2.0:\n","    precision: 0.7223024173541233\n","    recall: 0.6499498399895667\n","    f1-score: 0.6841406461042079\n","    support: 446.8\n","  accuracy: 0.7324927413368677\n","  macro avg:\n","    precision: 0.7308892948251\n","    recall: 0.7243982461986851\n","    f1-score: 0.726058822517075\n","    support: 1002.6\n","  weighted avg:\n","    precision: 0.7318230764506755\n","    recall: 0.7324927413368677\n","    f1-score: 0.7306165123260422\n","    support: 1002.6\n"]}]}]}